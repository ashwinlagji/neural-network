{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment_CIFAR_10.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "4T5h8exWl_LR",
        "yykRb1cTvjZt",
        "0ye3dyIW1RXQ"
      ],
      "authorship_tag": "ABX9TyMysRCvk9V7yz6q+MtHMAUV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinlagji/neural-network/blob/main/DL_Assignment_CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FMDaVEflhYB"
      },
      "source": [
        "# DL Assignemnt CIFAR 10 using DL\n",
        "\n",
        "### Question No.1.\n",
        "Vision Dataset: CIFAR-10- It dataset consists of 60000 32x32 colour images in 10 classes.\n",
        "Please find your dataset from the link- https://www.tensorflow.org/datasets/catalog/cifar10. (5 marks)\n",
        "Prepare a python notebook (recommended- use Google Colab) to build, train and evaluate a deep neural network on\n",
        "the CIFAR-10 dataset. Read the instructions carefully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T5h8exWl_LR"
      },
      "source": [
        "*** \n",
        "\n",
        "## 1. Import Libraries/Dataset \n",
        "-  Import required libraries (recommended- use tensorflow/keras library).\n",
        "-  Import the dataset (use Google Drive if required).\n",
        "-  Check the GPU available (recommended- use free GPU provided by Google Colab)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLIrKkJjlLYM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(tf.test.gpu_device_name());\n",
        "print(device_lib.list_local_devices());\n",
        "\n",
        "print('Xtrain \\n', x_train[10,10])\n",
        "print('Xtest \\n', x_test[10,10])\n",
        "print('Ytrain \\n', y_train[10,])\n",
        "print('Ytest \\n', y_test[10,])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yykRb1cTvjZt"
      },
      "source": [
        "*** \n",
        "\n",
        "## 2. Data Visualization \n",
        "\n",
        "\n",
        "- Plot at least one sample from each class of the dataset (use matplotlib/seaborn/any other library).\n",
        "- Print the shapes of train and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh61y9G9v4Lu"
      },
      "source": [
        "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'];\n",
        "fig, axes = plt.subplots(ncols=7, nrows=3, figsize=(17, 8))\n",
        "index = 0\n",
        "for i in range(3):\n",
        "    for j in range(7):\n",
        "        axes[i,j].set_title(labels[y_train[index][0]])\n",
        "        axes[i,j].imshow(x_train[index])\n",
        "        axes[i,j].get_xaxis().set_visible(False)\n",
        "        axes[i,j].get_yaxis().set_visible(False)\n",
        "        index += 1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HS-X6R7uwVt"
      },
      "source": [
        "print('Shape of x_train is {}'.format(x_train.shape))\n",
        "print('Shape of x_test is {}'.format(x_test.shape))\n",
        "print('Shape of y_train is {}'.format(y_train.shape))\n",
        "print('Shape of y_test is {}'.format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ye3dyIW1RXQ"
      },
      "source": [
        "*** \n",
        "\n",
        "## 3. Data Pre-processing \n",
        "- Bring the train and test data in the required format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36IGlrzc1c3c"
      },
      "source": [
        "# Normalizing\n",
        "x_train = x_train.reshape((50000, 32*32*3)) \n",
        "x_train = x_train.astype('float32') / 255\n",
        "\n",
        "x_test = x_test.reshape((10000, 32*32*3)) \n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "#One hot encoding\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "print(x_train[0])\n",
        "print(y_test_cat[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeLvp2vm3Us9"
      },
      "source": [
        "*** \n",
        "\n",
        "## 4. Model Building\n",
        "- Sequential Model layers- Use AT LEAST 3 dense layers with appropriate input for each. Choose the best number for hidden units and give reasons.\n",
        "- Add L2 regularization to all the layers.\n",
        "- Add one layer of dropout at the appropriate position and give reasons.\n",
        "- Choose the appropriate activation function for all the layers.\n",
        "- Print the model summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aQaWWi43p4R"
      },
      "source": [
        "# Create a model object\n",
        "\n",
        "dnnModel = models.Sequential()\n",
        "\n",
        "# Layer 1 = input layer\n",
        "# specify the input size in the first layer.\n",
        "\n",
        "dnnModel.add(layers.Dense(500, activation='relu', input_shape= (32*32*3,)))\n",
        "\n",
        "# Layer 2 = hidden layer \n",
        "dnnModel.add(layers.Dense(500, kernel_regularizer=regularizers.l2(0.0001) ,activation='relu'))\n",
        "\n",
        "# Layer 3 = hidden layer \n",
        "dnnModel.add(layers.Dense(500, kernel_regularizer=regularizers.l2(0.0001), activation='relu'))\n",
        "\n",
        "# Layer 4 = hidden layer \n",
        "dnnModel.add(layers.Dense(500, kernel_regularizer=regularizers.l2(0.0001),  activation='relu'))\n",
        "\n",
        "# Layer 5 = hidden layer \n",
        "dnnModel.add(layers.Dense(500, kernel_regularizer=regularizers.l2(0.0001),  activation='relu'))\n",
        "\n",
        "# Layer 6 = hidden layer \n",
        "dnnModel.add(layers.Dense(500, kernel_regularizer=regularizers.l2(0.0001),  activation='relu'))\n",
        "\n",
        "# Layer 7 = output layer\n",
        "dnnModel.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "dnnModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxluQYxDDWpB"
      },
      "source": [
        "***\n",
        "\n",
        "## 5. Model Compilation\n",
        "\n",
        "- Compile the model with the appropriate loss function.\n",
        "- Use an appropriate optimizer. Give reasons for the choice of learning rate and its value.\n",
        "- Use accuracy as metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgBWlvPcDhKL"
      },
      "source": [
        "#\n",
        "dnnModel.compile( optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrb4U7sAG56i"
      },
      "source": [
        "***\n",
        "\n",
        "### 6. Model Training \n",
        "- Train the model for an appropriate number of epochs (print the train and validation accuracy/loss for\n",
        "each epoch). Use the appropriate batch size.\n",
        "- Plot the loss and accuracy history graphs. Print the total time taken for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AuKrwcnRMqe"
      },
      "source": [
        "h  = dnnModel.fit( x_train , y_train_cat , epochs=50, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68FOOnq02VST"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMLpXxhLrDtn"
      },
      "source": [
        "***\n",
        "## 7. Model Evaluation\n",
        "- Print the final test/validation loss and accuracy.\n",
        "- Print confusion matrix and classification report for the validation dataset. Write a summary for the best and worst performing class and the overall trend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGL5Dut6RVzw"
      },
      "source": [
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "print('Final training loss \\t', h.history['loss'][-1])\n",
        "print('Final training accuracy ', h.history['accuracy'][-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpOxI-MJTun7"
      },
      "source": [
        "# testing the model\n",
        "\n",
        "testLoss, testAccuracy = dnnModel.evaluate( x_test, y_test_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGoqv6t0TyOH"
      },
      "source": [
        "print('Testing loss \\t', testLoss)\n",
        "print('Testing accuracy ', testAccuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}