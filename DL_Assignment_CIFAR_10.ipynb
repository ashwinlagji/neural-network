{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment_CIFAR_10.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpcccpnj80xYRvqJS8Sxg0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinlagji/neural-network/blob/main/DL_Assignment_CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FMDaVEflhYB"
      },
      "source": [
        "# DL Assignemnt CIFAR 10 using DL\n",
        "\n",
        "### Question No.1.\n",
        "Vision Dataset: CIFAR-10- It dataset consists of 60000 32x32 colour images in 10 classes.\n",
        "Please find your dataset from the link- https://www.tensorflow.org/datasets/catalog/cifar10. (5 marks)\n",
        "Prepare a python notebook (recommended- use Google Colab) to build, train and evaluate a deep neural network on\n",
        "the CIFAR-10 dataset. Read the instructions carefully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T5h8exWl_LR"
      },
      "source": [
        "*** \n",
        "\n",
        "## 1. Import Libraries/Dataset (0.25 mark)\n",
        "-  Import required libraries (recommended- use tensorflow/keras library).\n",
        "-  Import the dataset (use Google Drive if required).\n",
        "-  Check the GPU available (recommended- use free GPU provided by Google Colab)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLIrKkJjlLYM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMLpXxhLrDtn"
      },
      "source": [
        "2. Data Visualization (0.25 mark)\n",
        "a. Plot at least one sample from each class of the dataset (use matplotlib/seaborn/any other library).\n",
        "b. Print the shapes of train and test data.\n",
        "3. Data Pre-processing (0.25 mark)\n",
        "a. Bring the train and test data in the required format.\n",
        "4. Model Building (0.2*5 = 1 mark)\n",
        "a. Sequential Model layers- Use AT LEAST 3 dense layers with appropriate input for each. Choose the\n",
        "best number for hidden units and give reasons.\n",
        "b. Add L2 regularization to all the layers.\n",
        "c. Add one layer of dropout at the appropriate position and give reasons.\n",
        "d. Choose the appropriate activation function for all the layers.\n",
        "e. Print the model summary.\n",
        "5. Model Compilation (0.25 mark)\n",
        "a. Compile the model with the appropriate loss function.\n",
        "b. Use an appropriate optimizer. Give reasons for the choice of learning rate and its value.\n",
        "c. Use accuracy as metric.\n",
        "6. Model Training (0.5 + 0.5 = 1 mark)\n",
        "a. Train the model for an appropriate number of epochs (print the train and validation accuracy/loss for\n",
        "each epoch). Use the appropriate batch size.\n",
        "b. Plot the loss and accuracy history graphs. Print the total time taken for training.\n",
        "7. Model Evaluation (0.25 + 0.75 = 1 mark)\n",
        "a. Print the final test/validation loss and accuracy.\n",
        "b. Print confusion matrix and classification report for the validation dataset. Write a summary for the\n",
        "best and worst performing class and the overall trend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR6ZRzEirjj3"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2020 The TensorFlow Datasets Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"CIFAR datasets.\"\"\"\n",
        "\n",
        "import collections\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets.public_api as tfds\n",
        "\n",
        "# Shared constants\n",
        "_CIFAR_IMAGE_SIZE = 32\n",
        "_CIFAR_IMAGE_SHAPE = (_CIFAR_IMAGE_SIZE, _CIFAR_IMAGE_SIZE, 3)\n",
        "\n",
        "\n",
        "_CITATION = \"\"\"\\\n",
        "@TECHREPORT{Krizhevsky09learningmultiple,\n",
        "    author = {Alex Krizhevsky},\n",
        "    title = {Learning multiple layers of features from tiny images},\n",
        "    institution = {},\n",
        "    year = {2009}\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Cifar10(tfds.core.GeneratorBasedBuilder):\n",
        "  \"\"\"CIFAR-10.\"\"\"\n",
        "\n",
        "  VERSION = tfds.core.Version(\"3.0.2\")\n",
        "\n",
        "  def _info(self):\n",
        "    return tfds.core.DatasetInfo(\n",
        "        builder=self,\n",
        "        description=(\"The CIFAR-10 dataset consists of 60000 32x32 colour \"\n",
        "                     \"images in 10 classes, with 6000 images per class. There \"\n",
        "                     \"are 50000 training images and 10000 test images.\"),\n",
        "        features=tfds.features.FeaturesDict({\n",
        "            \"id\": tfds.features.Text(),\n",
        "            \"image\": tfds.features.Image(shape=_CIFAR_IMAGE_SHAPE),\n",
        "            \"label\": tfds.features.ClassLabel(num_classes=10),\n",
        "        }),\n",
        "        supervised_keys=(\"image\", \"label\"),\n",
        "        homepage=\"https://www.cs.toronto.edu/~kriz/cifar.html\",\n",
        "        citation=_CITATION,\n",
        "    )\n",
        "\n",
        "  @property\n",
        "  def _cifar_info(self):\n",
        "    return CifarInfo(\n",
        "        name=self.name,\n",
        "        url=\"https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\",\n",
        "        train_files=[\n",
        "            \"data_batch_1.bin\", \"data_batch_2.bin\", \"data_batch_3.bin\",\n",
        "            \"data_batch_4.bin\", \"data_batch_5.bin\"\n",
        "        ],\n",
        "        test_files=[\"test_batch.bin\"],\n",
        "        prefix=\"cifar-10-batches-bin/\",\n",
        "        label_files=[\"batches.meta.txt\"],\n",
        "        label_keys=[\"label\"],\n",
        "    )\n",
        "\n",
        "  def _split_generators(self, dl_manager):\n",
        "    \"\"\"Returns SplitGenerators.\"\"\"\n",
        "    cifar_path = dl_manager.download_and_extract(self._cifar_info.url)\n",
        "    cifar_info = self._cifar_info\n",
        "\n",
        "    cifar_path = os.path.join(cifar_path, cifar_info.prefix)\n",
        "\n",
        "    # Load the label names\n",
        "    for label_key, label_file in zip(cifar_info.label_keys,\n",
        "                                     cifar_info.label_files):\n",
        "      labels_path = os.path.join(cifar_path, label_file)\n",
        "      with tf.io.gfile.GFile(labels_path) as label_f:\n",
        "        label_names = [name for name in label_f.read().split(\"\\n\") if name]\n",
        "      self.info.features[label_key].names = label_names\n",
        "\n",
        "    # Define the splits\n",
        "    def gen_filenames(filenames):\n",
        "      for f in filenames:\n",
        "        yield os.path.join(cifar_path, f)\n",
        "\n",
        "    return [\n",
        "        tfds.core.SplitGenerator(\n",
        "            name=tfds.Split.TRAIN,\n",
        "            gen_kwargs={\n",
        "                \"split_prefix\": \"train_\",\n",
        "                \"filepaths\": gen_filenames(cifar_info.train_files)\n",
        "            }),\n",
        "        tfds.core.SplitGenerator(\n",
        "            name=tfds.Split.TEST,\n",
        "            gen_kwargs={\n",
        "                \"split_prefix\": \"test_\",\n",
        "                \"filepaths\": gen_filenames(cifar_info.test_files)\n",
        "            }),\n",
        "    ]\n",
        "\n",
        "  def _generate_examples(self, split_prefix, filepaths):\n",
        "    \"\"\"Generate CIFAR examples as dicts.\n",
        "    Shared across CIFAR-{10, 100}. Uses self._cifar_info as\n",
        "    configuration.\n",
        "    Args:\n",
        "      split_prefix (str): Prefix that identifies the split (e.g. \"tr\" or \"te\").\n",
        "      filepaths (list[str]): The files to use to generate the data.\n",
        "    Yields:\n",
        "      The cifar examples, as defined in the dataset info features.\n",
        "    \"\"\"\n",
        "    label_keys = self._cifar_info.label_keys\n",
        "    index = 0  # Using index as key since data is always loaded in same order.\n",
        "    for path in filepaths:\n",
        "      for labels, np_image in _load_data(path, len(label_keys)):\n",
        "        record = dict(zip(label_keys, labels))\n",
        "        # Note: \"id\" is only provided for the user convenience. To shuffle the\n",
        "        # dataset we use `index`, so that the sharding is compatible with\n",
        "        # earlier versions.\n",
        "        record[\"id\"] = \"{}{:05d}\".format(split_prefix, index)\n",
        "        record[\"image\"] = np_image\n",
        "        yield index, record\n",
        "        index += 1\n",
        "\n",
        "\n",
        "class Cifar100(Cifar10):\n",
        "  \"\"\"CIFAR-100 dataset.\"\"\"\n",
        "\n",
        "  VERSION = tfds.core.Version(\"3.0.2\")\n",
        "\n",
        "  @property\n",
        "  def _cifar_info(self):\n",
        "    return CifarInfo(\n",
        "        name=self.name,\n",
        "        url=\"https://www.cs.toronto.edu/~kriz/cifar-100-binary.tar.gz\",\n",
        "        train_files=[\"train.bin\"],\n",
        "        test_files=[\"test.bin\"],\n",
        "        prefix=\"cifar-100-binary/\",\n",
        "        label_files=[\"coarse_label_names.txt\", \"fine_label_names.txt\"],\n",
        "        label_keys=[\"coarse_label\", \"label\"],\n",
        "    )\n",
        "\n",
        "  def _info(self):\n",
        "    return tfds.core.DatasetInfo(\n",
        "        builder=self,\n",
        "        description=(\"This dataset is just like the CIFAR-10, except it has \"\n",
        "                     \"100 classes containing 600 images each. There are 500 \"\n",
        "                     \"training images and 100 testing images per class. The \"\n",
        "                     \"100 classes in the CIFAR-100 are grouped into 20 \"\n",
        "                     \"superclasses. Each image comes with a \\\"fine\\\" label \"\n",
        "                     \"(the class to which it belongs) and a \\\"coarse\\\" label \"\n",
        "                     \"(the superclass to which it belongs).\"),\n",
        "        features=tfds.features.FeaturesDict({\n",
        "            \"id\": tfds.features.Text(),\n",
        "            \"image\": tfds.features.Image(shape=_CIFAR_IMAGE_SHAPE),\n",
        "            \"label\": tfds.features.ClassLabel(num_classes=100),\n",
        "            \"coarse_label\": tfds.features.ClassLabel(num_classes=20),\n",
        "        }),\n",
        "        supervised_keys=(\"image\", \"label\"),\n",
        "        homepage=\"https://www.cs.toronto.edu/~kriz/cifar.html\",\n",
        "        citation=_CITATION,\n",
        "    )\n",
        "\n",
        "\n",
        "class CifarInfo(collections.namedtuple(\"_CifarInfo\", [\n",
        "    \"name\",\n",
        "    \"url\",\n",
        "    \"prefix\",\n",
        "    \"train_files\",\n",
        "    \"test_files\",\n",
        "    \"label_files\",\n",
        "    \"label_keys\",\n",
        "])):\n",
        "  \"\"\"Contains the information necessary to generate a CIFAR dataset.\n",
        "  Attributes:\n",
        "    name (str): name of dataset.\n",
        "    url (str): data URL.\n",
        "    prefix (str): path prefix within the downloaded and extracted file to look\n",
        "      for `train_files` and `test_files`.\n",
        "    train_files (list<str>): name of training files within `prefix`.\n",
        "    test_files (list<str>): name of test files within `prefix`.\n",
        "    label_files (list<str>): names of the label files in the data.\n",
        "    label_keys (list<str>): names of the label keys in the data.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "def _load_data(path, labels_number=1):\n",
        "  \"\"\"Yields (labels, np_image) tuples.\"\"\"\n",
        "  with tf.io.gfile.GFile(path, \"rb\") as f:\n",
        "    data = f.read()\n",
        "  offset = 0\n",
        "  max_offset = len(data) - 1\n",
        "  while offset < max_offset:\n",
        "    labels = np.frombuffer(data, dtype=np.uint8, count=labels_number,\n",
        "                           offset=offset).reshape((labels_number,))\n",
        "    # 1 byte per label, 1024 * 3 = 3072 bytes for the image.\n",
        "    offset += labels_number\n",
        "    img = (np.frombuffer(data, dtype=np.uint8, count=3072, offset=offset)\n",
        "           .reshape((3, _CIFAR_IMAGE_SIZE, _CIFAR_IMAGE_SIZE))\n",
        "           .transpose((1, 2, 0))\n",
        "          )\n",
        "    offset += 3072\n",
        "    yield labels, img\n",
        "\n",
        "\n",
        "cf = Cifar10();\n",
        "\n",
        "cf._info()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}